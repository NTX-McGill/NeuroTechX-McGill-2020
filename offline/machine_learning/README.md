# Machine Learning

## Classification Problem
We defined our classification problem to be a 10-class problem, where there were 9 classes for finger movement (representing all fingers excluding 1 thumb) and 1 class for no movement.

## Window sizes
We used different rolling window sizes of 200ms, 500ms, 1000ms, and noticed that increasing from 200ms to 500ms considerably improved accuracy, with the tradeoff of a noticeable response lag. Increasing from 500ms to 1000ms only gave a slight improvement to accuracy, likely because longer windows may accidentally capture several keypresses instead of one.

While we could have asked users to type slower, this would have made the product less useable, so we stuck to 500ms windows as the standard for typical trials and let the text prediction help supply additional information. Note that when we had good trials, we brought this back down to 200ms.

## Models tested
The best performing models were KNN and Logistic Regression. Each of these models consistently performed to acheive 75-85% accuracy with minimal tuning on regular trials. KNN achieved peak accuracy of 93.0% on 200ms good trials. However, LR converged much quicker, making it our go-to for rapid prototyping and experimenting with different features.

We also experimented with other models, including Random Forest and SVM. We found that Random Forest almost performed to the same degree as KNN and LR, but always a few points worse. SVM was not robust, had a very long training time, and was overall not well suited for the data.

## Confusion Matrix
Our confusion matrix revealed that the largest sources of error were cross-finger confusion, namely, pinkie-index confusion. This is likely due to the placement of the electrode tracking the index finger, since it was on a muscle on the outer side of the lower forearm.

![Confusion Matrix Matched with Heatmap](https://github.com/NTX-McGill/NeuroTechX-McGill-2020/blob/main/offline/machine_learning/confusion_matrix_and_heatmap.png)

A: Confusion matrices of KNN models trained on 500 ms windows of data from all the trials (top) and 200 ms windows from only the “good” trials (bottom).
B: Comparison between probability heatmap produced by the KNN model trained on the 500 ms, all trials dataset (top) and actual finger classes (bottom).

---

# Prediction Heatmaps
Prediction heatmaps, generated by simulate_prediction.py empowered us with a tool for three important parts of our process:

### 1. Visual Verification for Expected Model Behaviour
We aligned heatmaps with the corresponding signal (power not normalized) to quickly validate if the predictions the model was doing were reasonable. This was done to ensure that the model was making predictions based on signal character and not based off overfitting or by coincidence.

![Sample output with 2 heatmaps and 2 line graphs for signals](https://github.com/NTX-McGill/NeuroTechX-McGill-2020/blob/main/offline/machine_learning/simulate_prediction_sample_output.jpg)

Note that the x-axis for the line plots are based on indices of the segment of the EMG time-series data from the trial, while the x-axis for the heatmaps are based off of indices of the sliding window for predictions. These numbers enable us to map back the segment to the data used for further analysis (i.e. aren't significant for graphical purposes).

### 2. Deepening Understanding of Mislabeled Points

#### 2a. Giving more insight into commonly confused fingers:
In our confusion matrix, we understood that some fingers were occasionally confused with each other. For example, the pinkie would sometimes be labelled as index, due to electrode placement. With the heatmap, we can dig up explicit examples of when this happened, and give it deeper consideration.

#### 2b. Learning about the limitations of our model:
Heatmaps helped us refine our window size needed for prediction, as well as upper bounds on typing speed. This greatly supplemented the information we were getting based on the accuracies of the models given different varients of the data.
For example, in an extreme case of rapid typing, we can observe heatmaps like the one below:

![Poor predictions observed with fast typing](https://github.com/NTX-McGill/NeuroTechX-McGill-2020/blob/main/offline/machine_learning/simulate_prediction_rapid.jpg)

### 3. Prototyping Live Simulated Predictions with Software
Creating simulate_prediction.py was a milestone in realizing that heatmaps could be an incredibly useful tool for live analysis. Heatmaps of a similar style were produced on the dashboard to be displayed when the EMG armbands were responding to muscle potentials in real time. This provided a valuable form of neurofeedback to users, who could learn techniques to control the device with greater success (e.g. learning to make larger motions when typing with certain fingers or other needs based on the individual's unique physiology).
